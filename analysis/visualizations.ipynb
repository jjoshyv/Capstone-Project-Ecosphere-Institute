{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34afeb6",
   "metadata": {},
   "source": [
    "# ðŸŒ Air Quality â€” Visualizations\n",
    "This notebook generates static and interactive visualizations from the pipeline outputs (`data_lake/feature_sets/features.parquet`, `analysis_outputs/trends/*`, `analysis_outputs/forecasts/*`).\n",
    "\n",
    "Outputs produced by this notebook:\n",
    "- Static PNGs -> `analysis_outputs/figures/`\n",
    "- Interactive HTML maps -> `analysis_outputs/maps/`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Robust file-read helpers for the notebook\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "def try_read_parquet(path):\n",
    "    \"\"\"\n",
    "    Return a DataFrame if parquet exists and is readable, otherwise None.\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    try:\n",
    "        if p.exists():\n",
    "            df = pd.read_parquet(p)\n",
    "            return df\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to read parquet {p}: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        return None\n",
    "\n",
    "def try_read_csv(path, parse_dates=None, nrows_preview=0):\n",
    "    \"\"\"\n",
    "    Read CSV if present. If parse_dates is given, inspect file columns first\n",
    "    and only pass the parse_dates entries that actually exist (avoids ValueError).\n",
    "    Returns DataFrame or None on missing file / failure.\n",
    "    - path: Path or str\n",
    "    - parse_dates: None or list/tuple/str of column(s) to parse as dates\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    try:\n",
    "        if not p.exists():\n",
    "            return None\n",
    "\n",
    "        # If parse_dates is provided, check which of those columns exist in the file\n",
    "        cols_to_parse = None\n",
    "        if parse_dates:\n",
    "            # read only header to inspect column names (fast)\n",
    "            preview = pd.read_csv(p, nrows=nrows_preview)\n",
    "            available_cols = set(preview.columns.tolist())\n",
    "            if isinstance(parse_dates, (list, tuple)):\n",
    "                cols_to_parse = [c for c in parse_dates if c in available_cols]\n",
    "            else:\n",
    "                cols_to_parse = [parse_dates] if parse_dates in available_cols else []\n",
    "        # actually read with guarded parse_dates\n",
    "        if cols_to_parse:\n",
    "            return pd.read_csv(p, parse_dates=cols_to_parse)\n",
    "        else:\n",
    "            # read without parse_dates to avoid ValueError\n",
    "            return pd.read_csv(p)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to read CSV {p}: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        return None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Auto-detected paths and safe loading using the helpers above\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'data_lake').exists():\n",
    "    project_root = cwd\n",
    "elif (cwd.parent / 'data_lake').exists():\n",
    "    project_root = cwd.parent\n",
    "else:\n",
    "    # fallback: if PROJECT_ROOT variable already set in notebook use it\n",
    "    try:\n",
    "        project_root\n",
    "    except NameError:\n",
    "        project_root = cwd  # last resort: assume current working dir\n",
    "    # we don't raise here to keep notebook non-fatal; prints follow\n",
    "\n",
    "print('Detected project root:', project_root)\n",
    "\n",
    "# default paths (adjust if your pipeline writes elsewhere)\n",
    "features_path = project_root / 'data_lake/feature_sets/features.parquet'\n",
    "trend_summary_path = project_root / 'analysis_outputs/trends/trend_summary.csv'\n",
    "forecast_summary_path = project_root / 'analysis_outputs/forecasts/forecast_summary.csv'\n",
    "\n",
    "# Use the robust helpers\n",
    "df_features = try_read_parquet(features_path)\n",
    "trend_summary = try_read_csv(trend_summary_path, parse_dates=['date'])\n",
    "forecast_summary = try_read_csv(forecast_summary_path, parse_dates=['date'])\n",
    "\n",
    "print('features:', 'found' if df_features is not None else 'missing')\n",
    "print('trend_summary:', 'found' if trend_summary is not None else 'missing')\n",
    "print('forecast_summary:', 'found' if forecast_summary is not None else 'missing')\n",
    "\n",
    "if df_features is not None:\n",
    "    print('âœ… features shape:', df_features.shape)\n",
    "    print('Columns:', df_features.columns.tolist())\n",
    "\n",
    "# If a CSV was read without parse_dates but you want to parse later safely:\n",
    "if trend_summary is not None and 'date' in trend_summary.columns and not pd.api.types.is_datetime64_any_dtype(trend_summary['date']):\n",
    "    trend_summary['date'] = pd.to_datetime(trend_summary['date'], errors='coerce')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a57e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: folium in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (0.20.0)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting python-pptx\n",
      "  Using cached python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-2.11.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from folium) (0.8.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from folium) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from folium) (2.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from folium) (2.32.5)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from folium) (2025.10.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from python-pptx) (11.1.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Using cached xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting lxml>=3.1.0 (from python-pptx)\n",
      "  Using cached lxml-6.0.2-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from python-pptx) (4.15.0)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from jinja2>=2.9->folium) (3.0.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from requests->folium) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from requests->folium) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from requests->folium) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\envs\\modis_env\\lib\\site-packages (from requests->folium) (2025.10.5)\n",
      "Downloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   -- ------------------------------------- 0.5/9.9 MB 172.9 kB/s eta 0:00:55\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   --- ------------------------------------ 0.8/9.9 MB 186.4 kB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 195.0 kB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 189.0 kB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 189.0 kB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 189.0 kB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 189.0 kB/s eta 0:00:46\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 1.6/9.9 MB 204.6 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 1.8/9.9 MB 200.1 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 1.8/9.9 MB 200.1 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 1.8/9.9 MB 200.1 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 1.8/9.9 MB 200.1 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 1.8/9.9 MB 200.1 kB/s eta 0:00:41\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 2.1/9.9 MB 202.8 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   --------- ------------------------------ 2.4/9.9 MB 203.0 kB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 203.2 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 205.6 kB/s eta 0:00:35\n",
      "   ------------ --------------------------- 3.1/9.9 MB 204.1 kB/s eta 0:00:34\n",
      "   ------------ --------------------------- 3.1/9.9 MB 204.1 kB/s eta 0:00:34\n",
      "   ------------ --------------------------- 3.1/9.9 MB 204.1 kB/s eta 0:00:34\n",
      "   ------------- -------------------------- 3.4/9.9 MB 211.7 kB/s eta 0:00:31\n",
      "   ------------- -------------------------- 3.4/9.9 MB 211.7 kB/s eta 0:00:31\n",
      "   ------------- -------------------------- 3.4/9.9 MB 211.7 kB/s eta 0:00:31\n",
      "   ------------- -------------------------- 3.4/9.9 MB 211.7 kB/s eta 0:00:31\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   -------------- ------------------------- 3.7/9.9 MB 216.8 kB/s eta 0:00:29\n",
      "   --------------- ------------------------ 3.9/9.9 MB 213.7 kB/s eta 0:00:28\n",
      "   --------------- ------------------------ 3.9/9.9 MB 213.7 kB/s eta 0:00:28\n",
      "   --------------- ------------------------ 3.9/9.9 MB 213.7 kB/s eta 0:00:28\n",
      "   --------------- ------------------------ 3.9/9.9 MB 213.7 kB/s eta 0:00:28\n",
      "   --------------- ------------------------ 3.9/9.9 MB 213.7 kB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 4.2/9.9 MB 215.3 kB/s eta 0:00:27\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------ --------------------- 4.5/9.9 MB 211.5 kB/s eta 0:00:26\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 4.7/9.9 MB 208.0 kB/s eta 0:00:25\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   -------------------- ------------------- 5.0/9.9 MB 205.2 kB/s eta 0:00:24\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   --------------------- ------------------ 5.2/9.9 MB 204.7 kB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 201.3 kB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 199.8 kB/s eta 0:00:21\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------ --------------- 6.0/9.9 MB 198.1 kB/s eta 0:00:20\n",
      "   ------------------------- -------------- 6.3/9.9 MB 198.8 kB/s eta 0:00:19\n",
      "   ------------------------- -------------- 6.3/9.9 MB 198.8 kB/s eta 0:00:19\n",
      "   ------------------------- -------------- 6.3/9.9 MB 198.8 kB/s eta 0:00:19\n",
      "   ------------------------- -------------- 6.3/9.9 MB 198.8 kB/s eta 0:00:19\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   -------------------------- ------------- 6.6/9.9 MB 202.6 kB/s eta 0:00:17\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   --------------------------- ------------ 6.8/9.9 MB 201.9 kB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 201.7 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 196.3 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 196.3 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 196.3 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 196.3 kB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 196.3 kB/s eta 0:00:14\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 7.6/9.9 MB 198.7 kB/s eta 0:00:12\n",
      "   ------------------------------- -------- 7.9/9.9 MB 195.7 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 7.9/9.9 MB 195.7 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 7.9/9.9 MB 195.7 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 7.9/9.9 MB 195.7 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 7.9/9.9 MB 195.7 kB/s eta 0:00:11\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 8.1/9.9 MB 197.2 kB/s eta 0:00:09\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 8.4/9.9 MB 189.9 kB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 190.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 8.9/9.9 MB 186.7 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 9.2/9.9 MB 183.2 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.4/9.9 MB 183.5 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 9.4/9.9 MB 183.5 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 9.4/9.9 MB 183.5 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 9.4/9.9 MB 183.5 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 9.4/9.9 MB 183.5 kB/s eta 0:00:03\n",
      "   ---------------------------------------  9.7/9.9 MB 184.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  9.7/9.9 MB 184.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  9.7/9.9 MB 184.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  9.7/9.9 MB 184.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 9.9/9.9 MB 185.6 kB/s  0:00:50\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/914.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/914.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/914.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/914.9 kB ? eta -:--:--\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 524.3/914.9 kB 284.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ----- 786.4/914.9 kB 176.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 786.4/914.9 kB 176.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 786.4/914.9 kB 176.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 914.9/914.9 kB 174.8 kB/s  0:00:05\n",
      "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.2 MB 55.6 kB/s eta 0:00:31\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   -------------- ------------------------- 0.8/2.2 MB 54.0 kB/s eta 0:00:27\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 1.0/2.2 MB 66.2 kB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 77.7 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 78.1 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.8/2.2 MB 85.5 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 2.1/2.2 MB 91.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.1/2.2 MB 91.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.1/2.2 MB 91.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.1/2.2 MB 91.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.1/2.2 MB 91.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.2/2.2 MB 92.9 kB/s  0:00:23\n",
      "Using cached python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached lxml-6.0.2-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Downloading narwhals-2.11.0-py3-none-any.whl (423 kB)\n",
      "Using cached xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
      "Installing collected packages: XlsxWriter, widgetsnbextension, narwhals, lxml, jupyterlab_widgets, python-pptx, plotly, ipywidgets\n",
      "\n",
      "   ---------------------------------------- 0/8 [XlsxWriter]\n",
      "   ---------------------------------------- 0/8 [XlsxWriter]\n",
      "   ---------------------------------------- 0/8 [XlsxWriter]\n",
      "   ----- ---------------------------------- 1/8 [widgetsnbextension]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   ---------- ----------------------------- 2/8 [narwhals]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   --------------- ------------------------ 3/8 [lxml]\n",
      "   -------------------- ------------------- 4/8 [jupyterlab_widgets]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------- -------------- 5/8 [python-pptx]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ------------------------------ --------- 6/8 [plotly]\n",
      "   ----------------------------------- ---- 7/8 [ipywidgets]\n",
      "   ----------------------------------- ---- 7/8 [ipywidgets]\n",
      "   ----------------------------------- ---- 7/8 [ipywidgets]\n",
      "   ----------------------------------- ---- 7/8 [ipywidgets]\n",
      "   ---------------------------------------- 8/8 [ipywidgets]\n",
      "\n",
      "Successfully installed XlsxWriter-3.2.9 ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 lxml-6.0.2 narwhals-2.11.0 plotly-6.4.0 python-pptx-1.0.2 widgetsnbextension-4.0.15\n",
      "Figures to: C:\\Users\\HP\\Desktop\\Capstone Project\\analysis\\analysis_outputs\\figures\n",
      "Maps to: C:\\Users\\HP\\Desktop\\Capstone Project\\analysis\\analysis_outputs\\maps\n"
     ]
    }
   ],
   "source": [
    "# Run only if you need interactive libs (uncomment to install)\n",
    "! pip install plotly folium ipywidgets python-pptx\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create output folders\n",
    "FIG_DIR = Path(\"analysis_outputs/figures\")\n",
    "MAP_DIR = Path(\"analysis_outputs/maps\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Figures to:\", FIG_DIR.resolve())\n",
    "print(\"Maps to:\", MAP_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744e172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "def try_read_parquet(path):\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        return pd.read_parquet(p)\n",
    "    return None\n",
    "\n",
    "def try_read_csv(path, parse_dates=None):\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        return pd.read_csv(p, parse_dates=parse_dates)\n",
    "    return None\n",
    "\n",
    "def save_fig(fig, filename, dpi=150):\n",
    "    out = FIG_DIR / filename\n",
    "    fig.savefig(out, bbox_inches=\"tight\", dpi=dpi)\n",
    "    print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcbfbfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\HP\\Desktop\\Capstone Project\\analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7bc7128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project root: c:\\Users\\HP\\Desktop\\Capstone Project\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load safely\u001b[39;00m\n\u001b[32m     20\u001b[39m df_features = try_read_parquet(features_path)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m trend_summary = \u001b[43mtry_read_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrend_summary_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m forecast_summary = try_read_csv(forecast_summary_path)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfeatures:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfound\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtry_read_csv\u001b[39m\u001b[34m(path, parse_dates)\u001b[39m\n\u001b[32m     20\u001b[39m p = Path(path)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.exists():\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_usecols_names(\n\u001b[32m    156\u001b[39m             usecols,\n\u001b[32m    157\u001b[39m             \u001b[38;5;28mself\u001b[39m.names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._set_noconvert_columns()\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[39m, in \u001b[36mParserBase._validate_parse_dates_presence\u001b[39m\u001b[34m(self, columns)\u001b[39m\n\u001b[32m    233\u001b[39m missing_cols = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    235\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     )\n\u001b[32m    241\u001b[39m )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing column provided to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparse_dates\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    248\u001b[39m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[32m    250\u001b[39m ]\n",
      "\u001b[31mValueError\u001b[39m: Missing column provided to 'parse_dates': 'date'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Detect project root automatically\n",
    "root = Path.cwd()\n",
    "if (root / \"data_lake\").exists():\n",
    "    project_root = root\n",
    "elif (root.parent / \"data_lake\").exists():\n",
    "    project_root = root.parent\n",
    "else:\n",
    "    raise FileNotFoundError(\"Cannot find project root (no data_lake/ folder found)\")\n",
    "\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "# Build paths relative to project root\n",
    "features_path = project_root / \"data_lake/feature_sets/features.parquet\"\n",
    "trend_summary_path = project_root / \"analysis_outputs/trends/trend_summary.csv\"\n",
    "forecast_summary_path = project_root / \"analysis_outputs/forecasts/forecast_summary.csv\"\n",
    "\n",
    "# Load safely\n",
    "df_features = try_read_parquet(features_path)\n",
    "trend_summary = try_read_csv(trend_summary_path, parse_dates=['date'])\n",
    "forecast_summary = try_read_csv(forecast_summary_path)\n",
    "\n",
    "print(\"features:\", \"found\" if df_features is not None else \"missing\")\n",
    "print(\"trend_summary:\", \"found\" if trend_summary is not None else \"missing\")\n",
    "print(\"forecast_summary:\", \"found\" if forecast_summary is not None else \"missing\")\n",
    "\n",
    "if df_features is not None:\n",
    "    print(\"âœ… features shape:\", df_features.shape)\n",
    "    print(\"Columns:\", df_features.columns.tolist())\n",
    "else:\n",
    "    print(\"âš ï¸ features.parquet not found even under project root:\", features_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5cfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust file-read helpers for the notebook\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "def try_read_parquet(path):\n",
    "    \"\"\"\n",
    "    Return a DataFrame if parquet exists and is readable, otherwise None.\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    try:\n",
    "        if p.exists():\n",
    "            df = pd.read_parquet(p)\n",
    "            return df\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to read parquet {p}:\", e)\n",
    "        traceback.print_exc(limit=1)\n",
    "        return None\n",
    "\n",
    "def try_read_csv(path, parse_dates=None, nrows_preview=0):\n",
    "    \"\"\"\n",
    "    Read CSV if present. If parse_dates is given, inspect file columns first\n",
    "    and only pass the parse_dates columns that actually exist (avoids ValueError).\n",
    "    Returns DataFrame or None on missing file / failure.\n",
    "      - path: Path or str\n",
    "      - parse_dates: None or list/tuple/str of column(s) to parse as dates\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    try:\n",
    "        if not p.exists():\n",
    "            return None\n",
    "\n",
    "        # If parse_dates is provided, check which of those columns exist in the file\n",
    "        cols_to_parse = None\n",
    "        if parse_dates:\n",
    "            # read only header to inspect column names (fast)\n",
    "            preview = pd.read_csv(p, nrows=nrows_preview)  # nrows=0 returns only columns\n",
    "            available_cols = set(preview.columns.tolist())\n",
    "            if isinstance(parse_dates, (list, tuple)):\n",
    "                cols_to_parse = [c for c in parse_dates if c in available_cols]\n",
    "            else:\n",
    "                cols_to_parse = [parse_dates] if parse_dates in available_cols else []\n",
    "        # actually read with guarded parse_dates\n",
    "        if cols_to_parse:\n",
    "            return pd.read_csv(p, parse_dates=cols_to_parse)\n",
    "        else:\n",
    "            # read without parse_dates to avoid ValueError\n",
    "            return pd.read_csv(p)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to read CSV {p}: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6806c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project root: c:\\Users\\HP\\Desktop\\Capstone Project\n",
      "features: found\n",
      "trend_summary: found\n",
      "forecast_summary: found\n",
      "âœ… features shape: (120, 7)\n",
      "Columns: ['Date', 'location_inferred', 'O3_ug_m3', 'year', 'month', 'year_month', 'O3_ug_m3_rolling_60m']\n"
     ]
    }
   ],
   "source": [
    "# auto-detect project root (works if notebook runs from project root or analysis/ subfolder)\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if (cwd / \"data_lake\").exists():\n",
    "    project_root = cwd\n",
    "elif (cwd.parent / \"data_lake\").exists():\n",
    "    project_root = cwd.parent\n",
    "else:\n",
    "    # fallback: allow user to set manually (set PROJECT_ROOT variable), else raise\n",
    "    try:\n",
    "        project_root  # if previously set by user\n",
    "    except NameError:\n",
    "        raise FileNotFoundError(\n",
    "            \"Cannot detect project root (no data_lake/ folder found). \"\n",
    "            \"Either run notebook from project root or set project_root manually.\"\n",
    "        )\n",
    "\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "# paths relative to project root\n",
    "features_path = project_root / \"data_lake/feature_sets/features.parquet\"\n",
    "trend_summary_path = project_root / \"analysis_outputs/trends/trend_summary.csv\"\n",
    "forecast_summary_path = project_root / \"analysis_outputs/forecasts/forecast_summary.csv\"\n",
    "\n",
    "# Use the robust helpers\n",
    "df_features = try_read_parquet(features_path)\n",
    "trend_summary = try_read_csv(trend_summary_path, parse_dates=['date'])\n",
    "forecast_summary = try_read_csv(forecast_summary_path, parse_dates=['date'])\n",
    "\n",
    "print(\"features:\", \"found\" if df_features is not None else \"missing\")\n",
    "print(\"trend_summary:\", \"found\" if trend_summary is not None else \"missing\")\n",
    "print(\"forecast_summary:\", \"found\" if forecast_summary is not None else \"missing\")\n",
    "\n",
    "if df_features is not None:\n",
    "    print(\"âœ… features shape:\", df_features.shape)\n",
    "    print(\"Columns:\", df_features.columns.tolist())\n",
    "\n",
    "# If a CSV was read without parse_dates but you want to parse later:\n",
    "if trend_summary is not None and 'date' in trend_summary.columns and not pd.api.types.is_datetime64_any_dtype(trend_summary['date']):\n",
    "    trend_summary['date'] = pd.to_datetime(trend_summary['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21017e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: missing\n",
      "trend_summary: missing\n",
      "forecast_summary: missing\n"
     ]
    }
   ],
   "source": [
    "# Paths (adjust if your pipeline writes elsewhere)\n",
    "features_path = Path(\"data_lake/feature_sets/features.parquet\")\n",
    "trend_summary_path = Path(\"analysis_outputs/trends/trend_summary.csv\")\n",
    "forecast_summary_path = Path(\"analysis_outputs/forecasts/forecast_summary.csv\")\n",
    "# There may be per-location forecast CSVs: analysis_outputs/forecasts/forecast_<loc>.csv\n",
    "\n",
    "# Load\n",
    "df_features = try_read_parquet(features_path)\n",
    "trend_summary = try_read_csv(trend_summary_path, parse_dates=['date'])  # may be None\n",
    "forecast_summary = try_read_csv(forecast_summary_path)\n",
    "\n",
    "print(\"features:\", \"found\" if df_features is not None else \"missing\")\n",
    "print(\"trend_summary:\", \"found\" if trend_summary is not None else \"missing\")\n",
    "print(\"forecast_summary:\", \"found\" if forecast_summary is not None else \"missing\")\n",
    "\n",
    "# If df_features exists, print a quick preview\n",
    "if df_features is not None:\n",
    "    print(\"features shape:\", df_features.shape)\n",
    "    print(df_features.columns.tolist())\n",
    "    # Try to find a location column (common names used in pipeline)\n",
    "    loc_candidates = [c for c in df_features.columns if c.lower().startswith(\"loc\") or c.lower().startswith(\"region\")]\n",
    "    if loc_candidates:\n",
    "        location_col = loc_candidates[0]\n",
    "    else:\n",
    "        # fallback columns\n",
    "        location_col = 'location' if 'location' in df_features.columns else 'location_inferred' if 'location_inferred' in df_features.columns else None\n",
    "    print(\"Using location col:\", location_col)\n",
    "else:\n",
    "    location_col = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ce1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic time conversion\n",
    "if df_features is not None:\n",
    "    date_col = next((c for c in df_features.columns if c.lower() == 'date' or c.lower() == 'date_time' or c.lower()=='date'), 'date')\n",
    "    df_features[date_col] = pd.to_datetime(df_features[date_col])\n",
    "    display(df_features.head())\n",
    "\n",
    "    # If value col not auto-known, try to detect a numeric pollutant column\n",
    "    pollutant_candidates = [c for c in df_features.columns if c not in [date_col, location_col, 'year','month','year_month'] and pd.api.types.is_numeric_dtype(df_features[c])]\n",
    "    print(\"Numeric candidates:\", pollutant_candidates[:6])\n",
    "    value_col = pollutant_candidates[0] if pollutant_candidates else None\n",
    "    print(\"Using value_col:\", value_col)\n",
    "else:\n",
    "    value_col = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "108835fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No feature dataset or value column found. Skipping static trend plot.\n"
     ]
    }
   ],
   "source": [
    "if df_features is None or value_col is None:\n",
    "    print(\"âš ï¸ No feature dataset or value column found. Skipping static trend plot.\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    if location_col:\n",
    "        # plot each location lightly; if many locations, plot the aggregated trend\n",
    "        nloc = df_features[location_col].nunique()\n",
    "        if nloc <= 8:\n",
    "            sns.lineplot(data=df_features, x=date_col, y=value_col, hue=location_col, ax=ax, legend='brief')\n",
    "            ax.set_title(f\"{value_col} by location (time)\")\n",
    "        else:\n",
    "            # aggregate monthly global mean\n",
    "            agg = df_features.groupby(date_col)[value_col].mean().reset_index()\n",
    "            sns.lineplot(data=agg, x=date_col, y=value_col, ax=ax)\n",
    "            ax.set_title(f\"Average {value_col} (all locations)\")\n",
    "    else:\n",
    "        sns.lineplot(data=df_features, x=date_col, y=value_col, ax=ax)\n",
    "        ax.set_title(f\"{value_col} (time)\")\n",
    "\n",
    "    ax.set_ylabel(f\"{value_col} (units)\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    save_fig(fig, \"timeseries_trend.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8ef427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found forecast files: []\n",
      "No forecast files found; skip forecast plotting.\n"
     ]
    }
   ],
   "source": [
    "# Auto-detect per-location forecast CSVs\n",
    "forecast_dir = Path(\"analysis_outputs/forecasts\")\n",
    "forecast_files = sorted(list(forecast_dir.glob(\"forecast_*.csv\")))\n",
    "print(\"Found forecast files:\", [f.name for f in forecast_files])\n",
    "\n",
    "if forecast_files:\n",
    "    for fpath in forecast_files:\n",
    "        df_f = pd.read_csv(fpath, parse_dates=['date'])\n",
    "        loc = fpath.stem.replace(\"forecast_\",\"\")\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        # plot historical + forecast if historical in features\n",
    "        # Here we use forecast CSV that commonly includes 'y', 'yhat', 'yhat_lower','yhat_upper' or 'yhat'\n",
    "        if 'y' in df_f.columns:\n",
    "            sns.lineplot(data=df_f, x='date', y='y', ax=ax, label='hist (y)')\n",
    "        if 'yhat' in df_f.columns:\n",
    "            sns.lineplot(data=df_f, x='date', y='yhat', ax=ax, label='forecast (yhat)')\n",
    "            if 'yhat_lower' in df_f.columns and 'yhat_upper' in df_f.columns:\n",
    "                ax.fill_between(df_f['date'], df_f['yhat_lower'], df_f['yhat_upper'], alpha=0.25, label='conf interval')\n",
    "        ax.set_title(f\"Forecast â€” {loc}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(value_col if value_col else 'value')\n",
    "        plt.legend()\n",
    "        save_fig(fig, f\"forecast_{loc}.png\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No forecast files found; skip forecast plotting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475906bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Missing data for interactive plot.\n"
     ]
    }
   ],
   "source": [
    "# Create an interactive plotly time-series. Exports as HTML and shows in notebook.\n",
    "if df_features is None or value_col is None:\n",
    "    print(\"âš ï¸ Missing data for interactive plot.\")\n",
    "else:\n",
    "    if location_col and df_features[location_col].nunique() <= 8:\n",
    "        fig = px.line(df_features, x=date_col, y=value_col, color=location_col, title=f\"Interactive: {value_col} by location\")\n",
    "    else:\n",
    "        agg = df_features.groupby(date_col)[value_col].mean().reset_index()\n",
    "        fig = px.line(agg, x=date_col, y=value_col, title=f\"Interactive: Mean {value_col} across locations\")\n",
    "\n",
    "    html_out = FIG_DIR / \"interactive_trend.html\"\n",
    "    fig.write_html(str(html_out), include_plotlyjs='cdn')\n",
    "    print(\"Saved interactive plot to:\", html_out)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68035747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No forecast CSVs to create interactive plots.\n"
     ]
    }
   ],
   "source": [
    "if forecast_files:\n",
    "    for fpath in forecast_files:\n",
    "        df_f = pd.read_csv(fpath, parse_dates=['date'])\n",
    "        loc = fpath.stem.replace(\"forecast_\",\"\")\n",
    "        # prefer y and yhat\n",
    "        if 'yhat' in df_f.columns:\n",
    "            fig = go.Figure()\n",
    "            if 'y' in df_f.columns:\n",
    "                fig.add_trace(go.Scatter(x=df_f['date'], y=df_f['y'], name='historical'))\n",
    "            fig.add_trace(go.Scatter(x=df_f['date'], y=df_f['yhat'], name='forecast'))\n",
    "            if 'yhat_lower' in df_f.columns and 'yhat_upper' in df_f.columns:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=pd.concat([df_f['date'], df_f['date'][::-1]]),\n",
    "                    y=pd.concat([df_f['yhat_upper'], df_f['yhat_lower'][::-1]]),\n",
    "                    fill='toself', fillcolor='rgba(0,100,80,0.2)', line=dict(color='rgba(255,255,255,0)'),\n",
    "                    hoverinfo=\"skip\", showlegend=True, name='conf interval'))\n",
    "            fig.update_layout(title=f\"Forecast (interactive) - {loc}\", xaxis_title='date', yaxis_title=value_col)\n",
    "            out_html = FIG_DIR / f\"interactive_forecast_{loc}.html\"\n",
    "            fig.write_html(out_html, include_plotlyjs='cdn')\n",
    "            print(\"Saved:\", out_html)\n",
    "        else:\n",
    "            print(f\"Skipping interactive forecast for {fpath.name} (no yhat column)\")\n",
    "else:\n",
    "    print(\"No forecast CSVs to create interactive plots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17620a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No lat/lon columns found in features dataset. If you have lat/lon, add columns named e.g. 'lat'/'lon'.\n"
     ]
    }
   ],
   "source": [
    "# We need lat/lon columns. Try common names.\n",
    "lat_candidates = [c for c in (df_features.columns if df_features is not None else []) if 'lat' in c.lower()]\n",
    "lon_candidates = [c for c in (df_features.columns if df_features is not None else []) if 'lon' in c.lower() or 'lng' in c.lower()]\n",
    "\n",
    "if df_features is not None and lat_candidates and lon_candidates:\n",
    "    lat_col = lat_candidates[0]\n",
    "    lon_col = lon_candidates[0]\n",
    "    print(\"Using coords:\", lat_col, lon_col)\n",
    "\n",
    "    # pick a centre\n",
    "    center = [df_features[lat_col].mean(), df_features[lon_col].mean()]\n",
    "    m = folium.Map(location=center, zoom_start=6)\n",
    "    # Option 1: markers for last measurement per location\n",
    "    latest = df_features.sort_values(date_col).groupby(location_col).tail(1)\n",
    "    for _, r in latest.iterrows():\n",
    "        folium.CircleMarker([r[lat_col], r[lon_col]],\n",
    "                            radius=4, popup=f\"{location_col}:{r[location_col]} {value_col}:{r[value_col]}\",\n",
    "                            fill=True).add_to(m)\n",
    "    # Option 2: heatmap using all points\n",
    "    heat_data = df_features[[lat_col, lon_col, value_col]].dropna().values.tolist()\n",
    "    HeatMap(heat_data, radius=10).add_to(m)\n",
    "\n",
    "    map_out = MAP_DIR / \"aq_heatmap.html\"\n",
    "    m.save(map_out)\n",
    "    print(\"Saved map:\", map_out)\n",
    "else:\n",
    "    print(\"No lat/lon columns found in features dataset. If you have lat/lon, add columns named e.g. 'lat'/'lon'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a82c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote visualization manifest: analysis_outputs/visualization_manifest.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_at': '2025-11-11T16:40:07.177027Z',\n",
       " 'has_features': False,\n",
       " 'n_rows_features': 0,\n",
       " 'n_locations': 0,\n",
       " 'figures_dir': 'analysis_outputs\\\\figures',\n",
       " 'maps_dir': 'analysis_outputs\\\\maps'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save small summary files for report\n",
    "summary = {\n",
    "    \"generated_at\": datetime.utcnow().isoformat()+\"Z\",\n",
    "    \"has_features\": df_features is not None,\n",
    "    \"n_rows_features\": int(df_features.shape[0]) if df_features is not None else 0,\n",
    "    \"n_locations\": int(df_features[location_col].nunique()) if df_features is not None and location_col else 0,\n",
    "    \"figures_dir\": str(FIG_DIR),\n",
    "    \"maps_dir\": str(MAP_DIR),\n",
    "}\n",
    "with open(\"analysis_outputs/visualization_manifest.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Wrote visualization manifest: analysis_outputs/visualization_manifest.json\")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1242afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PPTX: analysis_outputs\\visualizations_summary.pptx\n"
     ]
    }
   ],
   "source": [
    "# Optional: create a simple PPTX containing the PNGs produced above.\n",
    "try:\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches\n",
    "    prs = Presentation()\n",
    "    prs.slide_height = Inches(7)\n",
    "    for png in sorted(FIG_DIR.glob(\"*.png\")):\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[6])  # blank\n",
    "        left = top = Inches(0.5)\n",
    "        pic = slide.shapes.add_picture(str(png), left, top, width=Inches(9))\n",
    "    ppt_out = Path(\"analysis_outputs/visualizations_summary.pptx\")\n",
    "    prs.save(ppt_out)\n",
    "    print(\"Saved PPTX:\", ppt_out)\n",
    "except Exception as e:\n",
    "    print(\"Skipping PPTX export (python-pptx not installed or error):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83b66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}